{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0096f84d",
   "metadata": {},
   "source": [
    "# Online Hard Example Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a344fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c951fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    a simple MLP with two hidden layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a58b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    \"\"\"\n",
    "    A custom data loader that subsamples the mini-batch based on high error. The MSELoss is used as \n",
    "    the loss function since this is a regression problem. The error is computed for each example in\n",
    "    the mini-batch using the loss, the examples are sorted based on the error, and a subset of \n",
    "    examples with high error is selected. The subsample_fraction hyperparameter determines the \n",
    "    fraction of examples to keep.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, subsample_fraction):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset: a PyTorch Dataset object\n",
    "        - batch_size: an integer indicating the batch size\n",
    "        - subsample_fraction: a float between 0 and 1 indicating the fraction of examples to use for \n",
    "            backpropagation\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.subsample_fraction = subsample_fraction\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Returns an iterator that generates subsampled minibatches from the dataset.\n",
    "        \"\"\"\n",
    "        indices = torch.randperm(len(self.dataset))\n",
    "        \n",
    "        # Iterates over the dataset and generates mini-batches starting from the index start to \n",
    "        # end, where start and end are defined by the batch size and the length of the dataset. \n",
    "        # The inputs and targets of the mini-batch are extracted from the dataset using \n",
    "        # the indices generated by indices[start:end].\n",
    "        for start in range(0, len(self.dataset), self.batch_size):\n",
    "            end = min(start + self.batch_size, len(self.dataset))\n",
    "            inputs, targets = self.dataset[indices[start:end]]\n",
    "\n",
    "            # torch.no_grad() used to turn off autograd for the duration of a block of code.\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                # Forward pass to obtain outputs and compute loss\n",
    "                outputs = model(inputs)\n",
    "                # calculate squared error\n",
    "                batch_loss = np.square(outputs - targets).numpy()\n",
    "                    \n",
    "                # get the index of the errors based on their size. Order in descending order\n",
    "                # - np.argsort() returns the indices that would sort an array. \n",
    "                #   np.argsort([3, 1, 4, 2]) would return [1, 3, 0, 2]\n",
    "                # - [-1:] changes order of indices to descending order of error.\n",
    "                #   the result is the array of indices that correspond to the examples with the \n",
    "                #   highest errors in the current minibatch\n",
    "                sorted_idx = np.argsort(batch_loss, axis=0)[::-1]\n",
    "                #print(sorted_idx)\n",
    "                \n",
    "                # selects a subset of these indices based on the subsample_fraction parameter,\n",
    "                # and the resulting subset_idx array is used to obtain a subset of the inputs \n",
    "                # and targets for backpropagation.\n",
    "                subset_idx = sorted_idx[:int(len(sorted_idx) * self.subsample_fraction)]\n",
    "                #print(subset_idx)\n",
    "\n",
    "            # Yield subsampled inputs and targets\n",
    "            yield inputs[subset_idx.flatten()], targets[subset_idx.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cd3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "model = MLP(input_size=10, hidden_size=64, output_size=1)\n",
    "\n",
    "# A randomly generated dataset is used for demonstration purposes, where each example has 10 features\n",
    "# and 1 target value.In total, there are 1000 sampleswith the input shape of (1000, 10) and a target \n",
    "# variable with shape (1000, 1). \n",
    "train_dataset = torch.utils.data.TensorDataset(torch.randn(1000, 10), torch.randn(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "227f96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_object(train_dataset, batch_size, subsample_fraction, lr, epochs):\n",
    "    \"\"\"\n",
    "    Trains a simple multi-layer perceptron (MLP) on a given dataset using Online Hard Example Mining\n",
    "    and the stochastic gradient descent (SGD) optimizer.\n",
    "\n",
    "    Args:\n",
    "    - train_dataset: torch.utils.data.Dataset object, training dataset.\n",
    "    - batch_size: int, mini-batch size.\n",
    "    - subsample_fraction: float between 0 and 1, fraction of hard examples to use during each training iteration.\n",
    "    - lr: float, learning rate of the SGD optimizer.\n",
    "    - epochs: int, number of epochs to train the model for.\n",
    "\n",
    "    Returns:\n",
    "    - train_losses_epoch: list of floats, average training loss per epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up the model\n",
    "    model = MLP(input_size=10, hidden_size=64, output_size=1)\n",
    "    \n",
    "    # Create a custom data loader object (train_loader) based on the CustomDataLoader class \n",
    "    # defined earlier. The train_loader object is initialized with the train_dataset object created in \n",
    "    # the previous line, a batch size of 32, and a subsample fraction of 0.5. This means that each \n",
    "    # minibatch will consist of 32 examples, and during each training iteration, only the top 50% of \n",
    "    # examples with the highest errors will be used for backpropagation.\n",
    "    train_loader = CustomDataLoader(train_dataset, batch_size, subsample_fraction)\n",
    "\n",
    "    # Creates a stochastic gradient descent (SGD) optimizer object that will be used to update the model \n",
    "    # parameters during training. \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize lists to store training loss and validation loss\n",
    "    train_losses_epoch = []\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize lists to store training loss and validation loss\n",
    "        train_losses_batch = []    \n",
    "        # generate sub-sampled mini batches of hard examples\n",
    "        for inputs, targets in train_loader:\n",
    "            # print(inputs.shape)\n",
    "            # Sets the gradients of all optimized torch.Tensor s to zero.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass mini batch\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs.shape)\n",
    "\n",
    "            # Calculate MSE loss\n",
    "            loss = nn.MSELoss()(outputs, targets)\n",
    "\n",
    "            # Back propagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Append training loss to list\n",
    "            train_losses_batch.append(loss.item())\n",
    "\n",
    "        # Append the average loss per batch to list of loss per epoch\n",
    "        train_losses_epoch.append(sum(train_losses_batch) / len(train_losses_batch))\n",
    "        print(f\"Epoch {epoch+1}: train_loss = {train_losses_epoch[-1]:.4f}\")\n",
    "    return train_losses_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc01ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss = 1.8564\n",
      "Epoch 2: train_loss = 1.8027\n",
      "Epoch 3: train_loss = 1.7367\n",
      "Epoch 4: train_loss = 1.7028\n",
      "Epoch 5: train_loss = 1.7636\n",
      "Epoch 6: train_loss = 1.6676\n",
      "Epoch 7: train_loss = 1.6247\n",
      "Epoch 8: train_loss = 1.5768\n",
      "Epoch 9: train_loss = 1.4915\n",
      "Epoch 10: train_loss = 1.4743\n",
      "Epoch 11: train_loss = 1.5240\n",
      "Epoch 12: train_loss = 1.5110\n",
      "Epoch 13: train_loss = 1.4520\n",
      "Epoch 14: train_loss = 1.4030\n",
      "Epoch 15: train_loss = 1.3546\n",
      "Epoch 16: train_loss = 1.3989\n",
      "Epoch 17: train_loss = 1.3375\n",
      "Epoch 18: train_loss = 1.2371\n",
      "Epoch 19: train_loss = 1.1971\n",
      "Epoch 20: train_loss = 1.1682\n",
      "Epoch 21: train_loss = 1.0306\n",
      "Epoch 22: train_loss = 1.1277\n",
      "Epoch 23: train_loss = 1.0551\n",
      "Epoch 24: train_loss = 1.0873\n",
      "Epoch 25: train_loss = 1.0595\n",
      "Epoch 26: train_loss = 1.0312\n",
      "Epoch 27: train_loss = 0.9988\n",
      "Epoch 28: train_loss = 0.8957\n",
      "Epoch 29: train_loss = 0.7521\n",
      "Epoch 30: train_loss = 0.7768\n",
      "Epoch 31: train_loss = 0.8730\n",
      "Epoch 32: train_loss = 0.7769\n",
      "Epoch 33: train_loss = 0.6674\n",
      "Epoch 34: train_loss = 0.6631\n",
      "Epoch 35: train_loss = 0.5989\n",
      "Epoch 36: train_loss = 0.5820\n",
      "Epoch 37: train_loss = 0.5768\n",
      "Epoch 38: train_loss = 0.5153\n",
      "Epoch 39: train_loss = 0.5310\n",
      "Epoch 40: train_loss = 0.4469\n",
      "Epoch 41: train_loss = 0.4526\n",
      "Epoch 42: train_loss = 0.4582\n",
      "Epoch 43: train_loss = 0.5080\n",
      "Epoch 44: train_loss = 0.4164\n",
      "Epoch 45: train_loss = 0.4022\n",
      "Epoch 46: train_loss = 0.4287\n",
      "Epoch 47: train_loss = 0.4256\n",
      "Epoch 48: train_loss = 0.3832\n",
      "Epoch 49: train_loss = 0.3560\n",
      "Epoch 50: train_loss = 0.3971\n",
      "Epoch 51: train_loss = 0.3727\n",
      "Epoch 52: train_loss = 0.3160\n",
      "Epoch 53: train_loss = 0.3686\n",
      "Epoch 54: train_loss = 0.3866\n",
      "Epoch 55: train_loss = 0.3526\n",
      "Epoch 56: train_loss = 0.2364\n",
      "Epoch 57: train_loss = 0.2935\n",
      "Epoch 58: train_loss = 0.3103\n",
      "Epoch 59: train_loss = 0.2443\n",
      "Epoch 60: train_loss = 0.1723\n",
      "Epoch 61: train_loss = 0.1885\n",
      "Epoch 62: train_loss = 0.1836\n",
      "Epoch 63: train_loss = 0.1846\n",
      "Epoch 64: train_loss = 0.1759\n",
      "Epoch 65: train_loss = 0.2490\n",
      "Epoch 66: train_loss = 0.1555\n",
      "Epoch 67: train_loss = 0.1289\n",
      "Epoch 68: train_loss = 0.1630\n",
      "Epoch 69: train_loss = 0.1326\n",
      "Epoch 70: train_loss = 0.1281\n",
      "Epoch 71: train_loss = 0.1185\n",
      "Epoch 72: train_loss = 0.1424\n",
      "Epoch 73: train_loss = 0.1163\n",
      "Epoch 74: train_loss = 0.1166\n",
      "Epoch 75: train_loss = 0.1116\n",
      "Epoch 76: train_loss = 0.0960\n",
      "Epoch 77: train_loss = 0.0923\n",
      "Epoch 78: train_loss = 0.0780\n",
      "Epoch 79: train_loss = 0.1166\n",
      "Epoch 80: train_loss = 0.1204\n",
      "Epoch 81: train_loss = 0.1422\n",
      "Epoch 82: train_loss = 0.1196\n",
      "Epoch 83: train_loss = 0.1008\n",
      "Epoch 84: train_loss = 0.0804\n",
      "Epoch 85: train_loss = 0.0935\n",
      "Epoch 86: train_loss = 0.0707\n",
      "Epoch 87: train_loss = 0.1054\n",
      "Epoch 88: train_loss = 0.0977\n",
      "Epoch 89: train_loss = 0.1971\n",
      "Epoch 90: train_loss = 0.1068\n",
      "Epoch 91: train_loss = 0.0868\n",
      "Epoch 92: train_loss = 0.0901\n",
      "Epoch 93: train_loss = 0.0974\n",
      "Epoch 94: train_loss = 0.0687\n",
      "Epoch 95: train_loss = 0.0557\n",
      "Epoch 96: train_loss = 0.0439\n",
      "Epoch 97: train_loss = 0.0351\n",
      "Epoch 98: train_loss = 0.0333\n",
      "Epoch 99: train_loss = 0.0345\n",
      "Epoch 100: train_loss = 0.0847\n"
     ]
    }
   ],
   "source": [
    "# A randomly generated dataset is used for demonstration purposes, where each example has 10 features\n",
    "# and 1 target value.In total, there are 1000 sampleswith the input shape of (1000, 10) and a target \n",
    "# variable with shape (1000, 1). \n",
    "train_dataset = torch.utils.data.TensorDataset(torch.randn(1000, 10), torch.randn(1000, 1))\n",
    "\n",
    "train_losses_epoch = train_object(train_dataset, batch_size = 32,\n",
    "                                  subsample_fraction = 0.5, lr = 0.1, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f54864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(train_losses_epoch, label=\"train\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54c919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
